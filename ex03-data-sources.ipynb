{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Data sources\n",
    "- All files used in this exercise can be found under the Exercises/data_files directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Use gamedata.json for this task. This file contains information of games sold through Steam. Parse out the following information from the data (Important: Do not combine these filters, but do them separately!):\n",
    "- TOP 3 highest metacritic score. Present results using the following format: *Title* has metacritic score of *Score* (for example)\n",
    "- Games with price discount being 90 % or more. Present results using the following format: *Title* | Discount: *Savings* (for example Metal Gear Solid V: Ground Zeroes | Discount: 90.090090)\n",
    "- Games having metacritic score higher than steam score. Present results using the following format: *Title* has metacritic score of *MetacriticScore* and steam score of *SteamRatingPercent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Wars: Knights of the Old Republic has metacritic score of 93\n",
      "Metal Gear Solid V: The Phantom Pain has metacritic score of 91\n",
      "Bayonetta has metacritic score of 90\n"
     ]
    }
   ],
   "source": [
    "# TOP 3 highest metacritic score\n",
    "import json\n",
    "\n",
    "with open ('./data_files/gamedata.json', 'r') as f:\n",
    "    games = json.load(f)\n",
    "\n",
    "top_3_games = sorted(\n",
    "    games,\n",
    "    key=lambda i: int(i[\"metacriticScore\"]),\n",
    "    reverse=True\n",
    ")[:3]\n",
    "\n",
    "for game in top_3_games:\n",
    "    print(f\"{game['title']} has metacritic score of {game['metacriticScore']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow Tactics: Blades of the Shogun | Discount: 90.022506\n",
      "Airscape: The Fall of Gravity | Discount: 90.180361\n",
      "Making History: The Calm and the Storm | Discount: 90.180361\n",
      "Avencast: Rise of the Mage | Discount: 90.090090\n",
      "Metal Gear Solid V: Ground Zeroes | Discount: 90.045023\n",
      "The Way | Discount: 90.060040\n",
      "Teslagrad | Discount: 90.090090\n",
      "White Wings  | Discount: 90.045023\n",
      "Phantaruk | Discount: 90.180361\n",
      "Oozi Earth Adventure | Discount: 90.180361\n",
      "Lucius | Discount: 90.090090\n",
      "The Long Journey Home | Discount: 90.045023\n",
      "NEON STRUCT | Discount: 90.050028\n",
      "House of Caravan | Discount: 90.180361\n"
     ]
    }
   ],
   "source": [
    "# Games with price discount being 90 % or more\n",
    "\n",
    "for game in games:\n",
    "    if float(game['savings']) >= 90:\n",
    "        print(f\"{game['title']} | Discount: {game['savings']}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBA 2K21 has metacritic score of 67 and steam score of 39\n",
      "Commander 85 has metacritic score of 45 and steam score of 35\n",
      "Inversion has metacritic score of 59 and steam score of 57\n",
      "Bionic Commando: Rearmed has metacritic score of 86 and steam score of 71\n",
      "Metal Gear Solid V: The Phantom Pain has metacritic score of 91 and steam score of 90\n",
      "Port Royale 2 has metacritic score of 75 and steam score of 68\n",
      "Project Cars 2 has metacritic score of 84 and steam score of 79\n",
      "Full Spectrum Warrior has metacritic score of 80 and steam score of 65\n",
      "The Long Journey Home has metacritic score of 68 and steam score of 60\n",
      "Star Wars: Knights of the Old Republic has metacritic score of 93 and steam score of 90\n",
      "Starpoint Gemini Warlords has metacritic score of 73 and steam score of 72\n",
      "Tidalis has metacritic score of 75 and steam score of 70\n"
     ]
    }
   ],
   "source": [
    "# Games having metacritic score higher than steam score\n",
    "\n",
    "for game in games:\n",
    "    if float(game['metacriticScore']) > float(game['steamRatingPercent']):\n",
    "        print(f\"{game['title']} has metacritic score of {game['metacriticScore']} and steam score of {game['steamRatingPercent']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Use earthquakes.csv for this task. This file contains information about earthquakes recorded between 1965 and 2016. Earthquake magnitude value describes how strong the earthquake is. Magnitude information can be categorized like presented in the table below (*Source: http://www.geo.mtu.edu/UPSeis/magnitude.html*).\n",
    "\n",
    "| Magnitude       | Class | Effects |\n",
    "|-----------------|-------|---------|\n",
    "| 2.49 or less    | Minor | Usually not felt, but can be recorded by seismograph. |\n",
    "| 2.50 to 5.49    | Light | Often felt, but only causes minor damage. |\n",
    "| 5.50 to 6.09    | Moderate | Slight damage to buildings and other structures. |\n",
    "| 6.10 to 6.99    | Strong | May cause a lot of damage in very populated areas. |\n",
    "| 7.00 to 7.99    | Major | Major earthquake. Serious damage. |\n",
    "| 8.00 or greater | Great | Great earthquake. Can totally destroy communities near the epicenter. |\n",
    "\n",
    "Count how many earthquakes have occurred in each class.\n",
    "\n",
    "<b style=\"color:red;\">Notice:</b> The first value has been modified to be 2.4 or less compared to the original source (has been 2.5 or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Minor': 0, 'Light': 0, 'Moderate': 17639, 'Strong': 5035, 'Major': 698, 'Great': 40}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open ('data_files/earthquakes.csv', 'r') as f:\n",
    "    rows = list(csv.reader(f, delimiter=\",\"))\n",
    "\n",
    "titles = rows[0]\n",
    "max_idx = titles.index('Magnitude')\n",
    "\n",
    "counts = {\n",
    "    \"Minor\": 0,\n",
    "    \"Light\": 0,\n",
    "    \"Moderate\": 0,\n",
    "    \"Strong\": 0,\n",
    "    \"Major\": 0,\n",
    "    \"Great\": 0\n",
    "}\n",
    "\n",
    "for row in rows[1:]:\n",
    "    magnitude = float(row[max_idx])\n",
    "\n",
    "    if magnitude <= 2.49:\n",
    "        counts['Minor'] += 1\n",
    "    elif 2.50 <= magnitude <= 5.49:\n",
    "        counts['Light'] += 1\n",
    "    elif 5.50 <= magnitude <= 6.09:\n",
    "        counts['Moderate'] += 1\n",
    "    elif 6.10 <= magnitude <= 6.99:\n",
    "        counts['Strong'] += 1\n",
    "    elif 7.00 <= magnitude <= 7.99:\n",
    "        counts['Major'] += 1\n",
    "    elif magnitude >= 8.00:\n",
    "        counts['Great'] += 1\n",
    "\n",
    "print(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Use netflix_titles.xml for this task. This file contains information about Netflix movies and TV shows. **Important:** Movies have duration presented in minutes while TV shows have duration presented in amount of seasons! Parse out the following information from the data and **show only counts** for these (how many instances are returned):\n",
    "- Movies released in 2017\n",
    "- TV show and movie amount (present both counts in separate lines)\n",
    "- Movies with a length between 15 and 20 minutes (values 15 and 20 included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744 movies released in 2017\n"
     ]
    }
   ],
   "source": [
    "# Movies released in 2017\n",
    "import xml.etree.ElementTree as et\n",
    "tree = et.parse(\"data_files/netflix_titles.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "\n",
    "count_2017 = 0\n",
    "for row in root:\n",
    "    media_type = row.find('type').text\n",
    "    release_year = row.find('release_year').text\n",
    "\n",
    "    if media_type == \"Movie\" and release_year == \"2017\":\n",
    "        count_2017 += 1\n",
    "\n",
    "print(f\"{count_2017} movies released in 2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Movie Count: 5377\n",
      "The Show Count: 2410\n"
     ]
    }
   ],
   "source": [
    "# TV show count\n",
    "\n",
    "show_count = 0\n",
    "movie_count = 0\n",
    "\n",
    "for item in root:\n",
    "    for detail in item:\n",
    "        if detail.tag == 'type' and detail.text == 'Movie':\n",
    "            movie_count += 1\n",
    "        elif  detail.tag == 'type' and detail.text == 'TV Show':\n",
    "            show_count += 1\n",
    "            \n",
    "print(f\"The Movie Count: {movie_count}\")       \n",
    "print(f\"The Show Count: {show_count}\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of movies duration 15-20 min: 11 \n"
     ]
    }
   ],
   "source": [
    "# Movies with a length between 15 and 20 minutes\n",
    "\n",
    "# Movies with a length between 15 and 20 minutes\n",
    "\n",
    "movies = []\n",
    "\n",
    "for item in root:  \n",
    "    is_movie = False\n",
    "    duration = \"\"\n",
    "    \n",
    "    for detail in item: \n",
    "        if detail.tag == 'type' and detail.text == 'Movie':\n",
    "            is_movie = True\n",
    "        if detail.tag == 'duration':\n",
    "            duration = detail.text\n",
    "    \n",
    "    if is_movie:\n",
    "        movies.append(duration)  \n",
    "\n",
    "\n",
    "count = 0\n",
    "for movie_duration in movies:\n",
    "    minutes = int(movie_duration.split(' ')[0])  \n",
    "    if 15 <= minutes <= 20:\n",
    "        count += 1\n",
    "\n",
    "print(f\"The count of movies duration 15-20 min: {count} \")   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Use the following Rest API for this task: https://tie.digitraffic.fi/api/weather/v1/stations/data. Calculate the average for air temperature (ILMA) and humidity (ILMAN_KOSTEUS) values using two decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature: -9.81°C\n",
      "Average humidity: 87.81%\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://tie.digitraffic.fi/api/weather/v1/stations/data'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "temperatures = []\n",
    "humidity = []\n",
    "\n",
    "for station in data['stations']:\n",
    "    for sensor in station['sensorValues']:\n",
    "        if sensor['name'] == 'ILMA':\n",
    "            temperatures.append(sensor['value'])\n",
    "        elif sensor['name'] == 'ILMAN_KOSTEUS':\n",
    "            humidity.append(sensor['value'])\n",
    "\n",
    "tmp_avg = sum(temperatures) / len(temperatures)\n",
    "humid_avg = sum(humidity) / len(humidity)\n",
    "\n",
    "print(f\"Average temperature: {tmp_avg:.2f}°C\")\n",
    "print(f\"Average humidity: {humid_avg:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 5 Use the following Rest API for this task: https://api.hel.fi/linkedevents/v1/place/. Fetch the data from **the first page** to this notebook. Then filter the data so that only places with postal code of 00100 or 00900 are included. Finally present the finnish name and street address of those places. For example: *Stoa | Turunlinnantie 1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keskustakirjasto Oodi | Töölönlahdenkatu 4\n",
      "Kampin palvelukeskus | Salomonkatu 21 B\n",
      "Itäkeskuksen kirjasto | Turunlinnantie 1\n",
      "Kampin liikuntakeskus | Malminkatu 3\n",
      "Stoa | Turunlinnantie 1\n",
      "Suomen Kansallisteatteri | Läntinen Teatterikuja 1\n",
      "Annantalo | Annankatu 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'https://api.hel.fi/linkedevents/v1/place/'\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "for place in data['data']:\n",
    "    postal_code = place['postal_code']\n",
    "    \n",
    "    if postal_code == \"00100\" or postal_code == \"00900\":\n",
    "        finnish_name = place['name']['fi']\n",
    "        street_address = place['street_address']['fi']\n",
    "        \n",
    "        print(f\"{finnish_name} | {street_address}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
